{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Flight Price Prediction Model**"
      ],
      "metadata": {
        "id": "e9tqUu9UqoBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr2JVysppUk6"
      },
      "outputs": [],
      "source": [
        "# 1. Loading the Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the flights dataset\n",
        "flights = pd.read_csv('flights.csv')\n",
        "\n",
        "# 2. Data Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Handle categorical variables\n",
        "encoder = OneHotEncoder()\n",
        "categorical_features = encoder.fit_transform(flights[['from', 'to', 'flightType', 'agency']])\n",
        "\n",
        "# Scale numerical features (removed 'age' as it's not in the flights dataset)\n",
        "scaler = StandardScaler()\n",
        "numerical_features = scaler.fit_transform(flights[['time', 'distance']])\n",
        "\n",
        "# Combine features\n",
        "X = np.concatenate([categorical_features.toarray(), numerical_features], axis=1)\n",
        "\n",
        "# Target variable\n",
        "y = flights['price'].values\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Feature Selection\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Select top k features\n",
        "selector = SelectKBest(f_regression, k='all')\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# 4. Model Training\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Train a regression model\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train_selected, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = regressor.predict(X_test_selected)\n",
        "\n",
        "# 5. Model Validation\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R^2 and RMSE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "print(f'R^2: {r2}')\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "# 6.Saving the Trained Model\n",
        "import joblib\n",
        "\n",
        "joblib.dump(regressor, 'flight_price_model.pkl')\n",
        "\n",
        "#7.Saving the Encoder and Scaler\n",
        "joblib.dump(encoder, 'encoder.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gender Classification Model**"
      ],
      "metadata": {
        "id": "4fDhwY6Gqh3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Loading the Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the users dataset\n",
        "users = pd.read_csv('users.csv')\n",
        "\n",
        "# 2. Data Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Handling categorical variables\n",
        "company_encoder = OneHotEncoder()\n",
        "company_features = company_encoder.fit_transform(users[['company']])\n",
        "\n",
        "# Scaling numerical features\n",
        "scaler = StandardScaler()\n",
        "age_feature = scaler.fit_transform(users[['age']])\n",
        "\n",
        "# Combine features\n",
        "X = np.concatenate([company_features.toarray(), age_feature], axis=1)\n",
        "\n",
        "# Target variable (gender)\n",
        "y = users['gender']\n",
        "\n",
        "# Encode target variable\n",
        "gender_encoder = LabelEncoder()\n",
        "y_encoded = gender_encoder.fit_transform(y)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Model Training\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train a classification model\n",
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# 4. Model Validation\n",
        "# Calculate accuracy and other metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(report)\n",
        "\n",
        "# 5. Saving the Trained Model\n",
        "import joblib\n",
        "\n",
        "joblib.dump(classifier, 'gender_classification_model.pkl')\n",
        "\n",
        "# 6. Saving the Encoder and Scaler\n",
        "joblib.dump(company_encoder, 'company_encoder.pkl')\n",
        "joblib.dump(scaler, 'age_scaler.pkl')\n",
        "joblib.dump(gender_encoder, 'gender_encoder.pkl')\n"
      ],
      "metadata": {
        "id": "52iYEKh5pWWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Travel Recommendation Model**"
      ],
      "metadata": {
        "id": "2QEDyBv8qwsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Loading the Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the hotels dataset\n",
        "hotels = pd.read_csv('hotels.csv')\n",
        "\n",
        "# 2. Data Preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode categorical features\n",
        "hotel_encoder = LabelEncoder()\n",
        "hotels['hotel_id'] = hotel_encoder.fit_transform(hotels['name'])\n",
        "\n",
        "user_encoder = LabelEncoder()\n",
        "hotels['user_id'] = user_encoder.fit_transform(hotels['userCode'])\n",
        "\n",
        "# 3. Feature Engineering\n",
        "data = hotels[['user_id', 'hotel_id', 'total']]\n",
        "\n",
        "# 4. Model Training\n",
        "# Using matrix factorization for collaborative filtering\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Create a matrix of users x hotels, filling missing values with zeros\n",
        "matrix = data.pivot_table(index='user_id', columns='hotel_id', values='total').fillna(0)\n",
        "\n",
        "# Determine the number of components\n",
        "num_components = min(matrix.shape) - 1  # One less than the smaller dimension of the matrix\n",
        "\n",
        "# Apply Truncated SVD for dimensionality reduction\n",
        "svd = TruncatedSVD(n_components=num_components, random_state=42)\n",
        "latent_matrix = svd.fit_transform(matrix)\n",
        "\n",
        "# 5. Model Evaluation\n",
        "reconstructed_matrix = svd.inverse_transform(latent_matrix)\n",
        "reconstruction_error = ((matrix - reconstructed_matrix) ** 2).mean()\n",
        "\n",
        "print(f'Reconstruction Error: {reconstruction_error}')\n",
        "\n",
        "# 6. Saving the Trained Model\n",
        "import joblib\n",
        "\n",
        "joblib.dump(svd, 'hotel_recommendation_model.pkl')\n",
        "joblib.dump(hotel_encoder, 'hotel_encoder.pkl')\n",
        "joblib.dump(user_encoder, 'user_encoder.pkl')\n"
      ],
      "metadata": {
        "id": "iDClP0uZpWrX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}